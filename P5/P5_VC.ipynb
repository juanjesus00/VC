{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\User\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "from deepface import DeepFace\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import FaceDetectors2\n",
    "import pygame\n",
    "\n",
    "FD = FaceDetectors2.FaceDetector()\n",
    "\n",
    "barba = cv2.imread('faces/barba3.webp', cv2.IMREAD_UNCHANGED)\n",
    "ceja_izquierda = cv2.imread('faces/ceja-izquierda.png', cv2.IMREAD_UNCHANGED)\n",
    "ceja_derecha = cv2.imread('faces/ceja-derecha.webp', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "barba = cv2.resize(barba,(barba.shape[1] // int(1.5), barba.shape[0]//1))\n",
    "ceja_izquierda = cv2.resize(ceja_izquierda, (ceja_izquierda.shape[1] // 2, ceja_izquierda.shape[0] // 2))\n",
    "ceja_derecha = cv2.resize(ceja_derecha, (ceja_derecha.shape[1] // 2, ceja_derecha.shape[0] // 2))\n",
    "\n",
    "\n",
    "\n",
    "def superponer_filtro(frame, filtro, x, y):\n",
    "    if x >= 0 and y >= 0 and \\\n",
    "        (x + filtro.shape[1] <= frame.shape[1]) and \\\n",
    "            (y + filtro.shape[0] <= frame.shape[0]):\n",
    "        \n",
    "        filtro_resized = cv2.resize(filtro, (int(filtro.shape[1]), int(filtro.shape[0])))\n",
    "        alpha = filtro_resized[:, :, 3] / 255.0\n",
    "\n",
    "        for c in range(0, 3):\n",
    "            frame[y:y + filtro_resized.shape[0], x:x + filtro_resized.shape[1], c] = \\\n",
    "            (\n",
    "                frame[y:y + filtro_resized.shape[0], x:x + filtro_resized.shape[1], c] * \n",
    "                (1 - alpha) + filtro_resized[:, :, c] * alpha\n",
    "            )\n",
    "\n",
    "# Conectar a la cámara web\n",
    "cap = cv2.VideoCapture(0)\n",
    "pygame.mixer.init()\n",
    "pygame.mixer.music.load('music/musicaFiltro1.mp3')\n",
    "pygame.mixer.music.play()\n",
    "while pygame.mixer.music.get_busy():\n",
    "    \n",
    "    pygame.mixer.music.set_volume(0.2)\n",
    "    # Capturar un fotograma de la cámara\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = cv2.merge([frame, frame, frame])\n",
    "    \n",
    "    \n",
    "    # Detección de rostro y ojos en el fotograma\n",
    "    values = FD.DetectLargestFaceEyesDNN(frame)\n",
    "    if values is not None:\n",
    "        face, eyes, shape = values\n",
    "\n",
    "        # Dibujar un marco alrededor del rostro\n",
    "        [x, y, w, h] = face\n",
    "        if x > -1:\n",
    "            [lex, ley, rex, rey] = eyes\n",
    "            if lex > -1:\n",
    "                superponer_filtro(frame, ceja_izquierda, shape[19][0] - ceja_izquierda.shape[1] // 2-10, shape[19][1] - ceja_izquierda.shape[0] // 2+10)\n",
    "                superponer_filtro(frame, ceja_derecha, shape[24][0] - ceja_derecha.shape[1] // 2+10, shape[24][1] - ceja_derecha.shape[0] // 2+10)\n",
    "                superponer_filtro(frame, barba, shape[51][0] - barba.shape[1] // 2, shape[51][1] - barba.shape[0] // 2 + 10)\n",
    "                \n",
    "\n",
    "    cv2.imshow('Cam', frame)\n",
    "    \n",
    "    # Esc para finalizar\n",
    "    tec = cv2.waitKey(40)\n",
    "    if tec == 27:  # Esc\n",
    "        pygame.mixer.music.stop()\n",
    "        break\n",
    "\n",
    "# Cerrar la ventana y liberar la cámara\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "import FaceDetectors2\n",
    "FD = FaceDetectors2.FaceDetector()\n",
    "\n",
    "majin = cv2.imread('faces/majin.png', cv2.IMREAD_UNCHANGED)\n",
    "ceja_izquierda = cv2.imread('faces/ceja-izquierda.png', cv2.IMREAD_UNCHANGED)\n",
    "ceja_derecha = cv2.imread('faces/ceja-derecha.webp', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "majin = cv2.resize(majin,(majin.shape[1] // 80, majin.shape[0] // 80))\n",
    "ceja_izquierda = cv2.resize(ceja_izquierda, (ceja_izquierda.shape[1] // 2, ceja_izquierda.shape[0] // 2))\n",
    "ceja_derecha = cv2.resize(ceja_derecha, (ceja_derecha.shape[1] // 2, ceja_derecha.shape[0] // 2))\n",
    "\n",
    "\n",
    "# Cargar el predictor de puntos de referencia faciales\n",
    "predictor_path = \"shape_predictor_68_face_landmarks.dat\"\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "# Inicializar el detector de caras de dlib\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "def superponer_filtro(frame, filtro, x, y):\n",
    "    if x >= 0 and y >= 0 and (x + filtro.shape[1] <= frame.shape[1]) and (y + filtro.shape[0] <= frame.shape[0]):\n",
    "        # Continúa con la superposición\n",
    "\n",
    "        \n",
    "        filtro_resized = cv2.resize(filtro, (int(filtro.shape[1]), int(filtro.shape[0])))\n",
    "        alpha = filtro_resized[:, :, 3] / 255.0\n",
    "\n",
    "        for c in range(0, 3):\n",
    "            frame[y:y + filtro_resized.shape[0], x:x + filtro_resized.shape[1], c] = \\\n",
    "            (\n",
    "                frame[y:y + filtro_resized.shape[0], x:x + filtro_resized.shape[1], c] * \n",
    "                (1 - alpha) + filtro_resized[:, :, c] * alpha\n",
    "            )\n",
    "# Función para detectar sonrisas\n",
    "def detectar_sonrisa(shape):\n",
    "    # Puntos de la boca (48-67)\n",
    "    boca = shape[48:68]\n",
    "    # Distancia horizontal entre las comisuras de la boca\n",
    "    ancho_boca = boca[7][0] - boca[0][0]\n",
    "    \n",
    "    # Distancia vertical entre el centro superior e inferior de la boca\n",
    "    altura_boca = boca[9][1] - boca[3][1]\n",
    "    # Si la altura es pequeña en comparación con el ancho, se considera una sonrisa\n",
    "    if altura_boca / ancho_boca < 0.3:  # Ajusta este umbral según sea necesario\n",
    "        \n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Capturar video desde la cámara\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "    for rect in rects:\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        \n",
    "        if detectar_sonrisa(shape):\n",
    "            \n",
    "            values = FD.DetectLargestFaceEyesDNN(frame)\n",
    "            if values is not None:\n",
    "                face, eyes, shape = values\n",
    "\n",
    "                # Dibujar un marco alrededor del rostro\n",
    "                [x, y, w, h] = face\n",
    "                if x > -1:\n",
    "                    [lex, ley, rex, rey] = eyes\n",
    "                    if lex > -1:\n",
    "                        superponer_filtro(frame, ceja_izquierda, shape[19][0] - ceja_izquierda.shape[1] // 2-10, shape[19][1] - ceja_izquierda.shape[0] // 2+10)\n",
    "                        superponer_filtro(frame, ceja_derecha, shape[24][0] - ceja_derecha.shape[1] // 2+10, shape[24][1] - ceja_derecha.shape[0] // 2+10)\n",
    "                        superponer_filtro(frame, majin, shape[24][0] - majin.shape[1] // 2 -38, shape[24][1] - majin.shape[0] // 2 -20)\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Deteccion de Sonrisa\", frame)\n",
    "\n",
    "    # Presionar Esc para salir\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import random\n",
    "import pygame\n",
    "\n",
    "# Cargar el detector de rostros de dlib\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# Cargar la imagen de superposición y el bloque\n",
    "overlay_image = cv2.imread(\"Minecraft/steve_face.png\", -1)  # Imagen que se pone en la cara\n",
    "# Cargar las imágenes y verificar si fueron cargadas correctamente\n",
    "diamond_image = cv2.imread(\"Minecraft/diamond.webp\", -1)  # Cargar con transparencia\n",
    "block_image = cv2.imread(\"Minecraft/tnt_redimensionada.png\", -1)\n",
    "\n",
    "pygame.mixer.init()\n",
    "pygame.mixer.music.load(\"Minecraft/hurt.mp3\")\n",
    "\n",
    "# Parámetros del juego\n",
    "lives = 3  # Vidas iniciales\n",
    "block_size = 50  # Tamaño de los bloques\n",
    "blocks = []  # Lista para almacenar los bloques\n",
    "\n",
    "# Configuración del bloque de caída\n",
    "class FallingBlock:\n",
    "    def __init__(self, x, y, speed, type):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.speed = speed\n",
    "        self.type = type\n",
    "\n",
    "    def move(self):\n",
    "        self.y += self.speed\n",
    "\n",
    "\n",
    "# Iniciar la webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convertir el frame a escala de grises (necesario para el detector de dlib)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detectar rostros\n",
    "    faces = detector(gray)\n",
    "\n",
    "    # Para cada rostro detectado\n",
    "    for face in faces:\n",
    "        # Coordenadas del rectángulo de la cara detectada\n",
    "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "\n",
    "        # Verificar si las coordenadas de la cara están dentro de los límites del frame\n",
    "        if x < 0 or y < 0 or x + w > frame.shape[1] or y + h > frame.shape[0]:\n",
    "            continue  # Si la cara está fuera de la pantalla, no hacer nada y pasar al siguiente rostro\n",
    "\n",
    "        # Cambiar el tamaño de la imagen de superposición para que coincida con la cara\n",
    "        overlay_resized = cv2.resize(overlay_image, (w, h))\n",
    "\n",
    "        # Obtener la región de la cara en el frame\n",
    "        face_region = frame[y:y+h, x:x+w]\n",
    "\n",
    "        # Convertir la imagen de superposición a BGRA (si tiene canal alpha)\n",
    "        if overlay_resized.shape[2] == 4:\n",
    "            overlay_bgr = overlay_resized[:, :, :3]\n",
    "            overlay_mask = overlay_resized[:, :, 3]  # Canal alpha\n",
    "        else:\n",
    "            overlay_bgr = overlay_resized\n",
    "            overlay_mask = np.ones(overlay_resized.shape[:2], dtype=np.uint8) * 255\n",
    "\n",
    "        # Crear una máscara inversa para superponer la imagen\n",
    "        overlay_inv_mask = cv2.bitwise_not(overlay_mask)\n",
    "\n",
    "        # Extraer la parte del frame donde colocaremos la imagen\n",
    "        # Verificar si el bloque está fuera de la pantalla\n",
    "        bg = cv2.bitwise_and(face_region, face_region, mask=overlay_inv_mask)\n",
    "            \n",
    "        # Extraer la parte de la imagen de superposición\n",
    "        fg = cv2.bitwise_and(overlay_bgr, overlay_bgr, mask=overlay_mask)\n",
    "\n",
    "        # Sumar ambas imágenes para crear la superposición\n",
    "        combined = cv2.add(bg, fg)\n",
    "\n",
    "        # Colocar la imagen combinada en el frame original\n",
    "        frame[y:y+h, x:x+w] = combined\n",
    "\n",
    "        # Detectar colisiones con los bloques\n",
    "        for block in blocks:\n",
    "            if (block.x < x + w and block.x + block_size > x and\n",
    "                block.y < y + h and block.y + block_size > y):\n",
    "\n",
    "                if block.type == \"diamond\":\n",
    "                    lives += 1\n",
    "                    pygame.mixer.music.load(\"Minecraft/gainlife.mp3\")\n",
    "                else:\n",
    "                    lives -= 1\n",
    "                    pygame.mixer.music.load(\"Minecraft/hurt.mp3\")\n",
    "\n",
    "                pygame.mixer.music.play()\n",
    "                blocks.remove(block)  # Eliminar el bloque que ha colisionado\n",
    "\n",
    "    # Generar bloques aleatoriamente\n",
    "    if random.random() < 0.03:  # Ajustar probabilidad de aparición\n",
    "        new_block = FallingBlock(random.randint(0, frame.shape[1] - block_size), 0, random.randint(2, 5), random.choice([\"diamond\", \"tnt\"]))\n",
    "        blocks.append(new_block)\n",
    "\n",
    "        # Mover y dibujar los bloques\n",
    "    for block in blocks:\n",
    "        block.move()\n",
    "        # Eliminar bloques fuera de la pantalla\n",
    "        if block.y > frame.shape[0]:\n",
    "            blocks.remove(block)\n",
    "        else:\n",
    "            # Cambiar tamaño de la imagen del bloque y dibujar\n",
    "            if block.type == \"diamond\":\n",
    "                block_resized = cv2.resize(diamond_image, (block_size, block_size))\n",
    "            else:\n",
    "                block_resized = cv2.resize(block_image, (block_size, block_size))\n",
    "\n",
    "            if block_resized.shape[2] == 3:  # Si la imagen tiene solo 3 canales (RGB)\n",
    "                alpha_channel = np.ones((block_resized.shape[0], block_resized.shape[1]), dtype=np.uint8) * 255\n",
    "                block_resized = cv2.merge([block_resized, alpha_channel])  # Agregar el canal alfa\n",
    "            \n",
    "            # Verifica si la imagen tiene 4 canales (BGRA con transparencia)\n",
    "            if block_resized.shape[2] == 4:\n",
    "                # Dividir los canales de block_resized (asumimos que es BGRA)\n",
    "                b, g, r, alpha = cv2.split(block_resized)\n",
    "                \n",
    "                # Crear la máscara y su inversa a partir del canal alfa\n",
    "                mask = alpha\n",
    "                mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "                # Combinar los canales BGR sin el canal alfa\n",
    "                block_resized_rgb = cv2.merge((b, g, r))\n",
    "\n",
    "                # Calcular las coordenadas en el frame donde colocaremos el bloque\n",
    "                y1, y2 = block.y, block.y + block_size\n",
    "                x1, x2 = block.x, block.x + block_size\n",
    "\n",
    "                if y2 <= 0 or y1 >= frame.shape[0] or x2 <= 0 or x1 >= frame.shape[1]:\n",
    "                    blocks.remove(block)\n",
    "                    continue  # Saltar al siguiente bloque\n",
    "\n",
    "                # Ajustar los límites si el bloque se sale de la pantalla\n",
    "                y1, y2 = max(0, y1), min(frame.shape[0], y2)\n",
    "                x1, x2 = max(0, x1), min(frame.shape[1], x2)\n",
    "\n",
    "                # Extraer la región de fondo donde se colocará el bloque\n",
    "                bg = cv2.bitwise_and(frame[y1:y2, x1:x2], frame[y1:y2, x1:x2], mask=mask_inv[:y2-y1, :x2-x1])\n",
    "                fg = cv2.bitwise_and(block_resized_rgb[:y2-y1, :x2-x1], block_resized_rgb[:y2-y1, :x2-x1], mask=mask[:y2-y1, :x2-x1])\n",
    "\n",
    "                # Sumar las imágenes de fondo y primer plano\n",
    "                combined = cv2.add(bg, fg)\n",
    "\n",
    "                # Colocar la imagen combinada en el frame original\n",
    "                frame[y1:y2, x1:x2] = combined\n",
    "            else:\n",
    "                print(\"Error: la imagen del bloque no tiene canal alpha\")\n",
    "\n",
    "\n",
    "    # Dibujar el contador de vidas en la esquina superior izquierda\n",
    "    cv2.putText(frame, f'Vidas: {lives}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    # Mostrar el frame resultante\n",
    "    cv2.imshow(\"Face Overlay with Falling Blocks\", frame)\n",
    "\n",
    "    # Salir si no hay vidas o si se presiona 'q'\n",
    "    if lives <= 0 or cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        # Crear una pantalla de \"Game Over\"\n",
    "        game_over_screen = np.zeros_like(frame)  # Pantalla negra del mismo tamaño que el frame\n",
    "        cv2.putText(game_over_screen, \"Game Over\", (int(frame.shape[1] / 4), int(frame.shape[0] / 2)), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 4)  # Texto de \"Game Over\" en rojo\n",
    "\n",
    "        # Mostrar la pantalla de \"Game Over\" durante 2 segundos\n",
    "        for _ in range(60):  # 60 frames (asumiendo aproximadamente 30 FPS)\n",
    "            cv2.imshow(\"Face Overlay with Falling Blocks\", game_over_screen)\n",
    "            if cv2.waitKey(30) & 0xFF == ord('q'):  # Permite salir antes si se presiona 'q'\n",
    "                break\n",
    "\n",
    "        break  # Salir del bucle principal del juego\n",
    "\n",
    "# Liberar la cámara y cerrar ventanas\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
