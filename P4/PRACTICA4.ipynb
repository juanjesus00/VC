{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la entrega de esta práctica, la tarea consiste en desarrollar un prototipo que procese uno (vídeo ejemplo proporcionado) o varios vídeos (incluyendo vídeos de cosecha propia):\n",
    "\n",
    "detecte y siga las personas y vehículos presentes\n",
    "detecte y lea las matrículas de los vehículos presentes\n",
    "cuente el total de cada clase\n",
    "vuelque a disco un vídeo que visualice los resultados\n",
    "genere un archivo csv con el resultado de la detección y seguimiento. Se sugiere un formato con al menos los siguientes campos:\n",
    "\n",
    "fotograma, tipo_objeto, confianza, identificador_tracking, x1, y1, x2, y2, matrícula_en_su_caso, confianza, mx1,my1,mx2,my2, texto_matricula\n",
    "\n",
    "La entrega del cuaderno o cuadernos se hace efectiva a través del campus virtual por medio de un enlace github. Además del archivo README, debe incluirse el resultado del vídeo proporcionado como test (o enlace al mismo), y el correspondiente archivo csv. En el caso de entrenarse algún detector, por ejemplo de matrículas, debe proporcionarse acceso al conjunto de datos.\n",
    "\n",
    "Se considerarán extras:\n",
    "\n",
    "Determine el flujo de personas y vehículos en el vídeo de test en distintas direcciones (vehículos que dejan la imagen por la derecha, por la izquierda, etc.)\n",
    "\n",
    "Evaluar dos alternativas para la detección de matrículas: basada en YOLO, y basada en contornos.\n",
    "\n",
    "Anonimizar a las personas y vehículos presentes en un vídeo.\n",
    "\n",
    "En el caso de haberse apuntado al Autumn Campus Makeathon InnovAction Canarias, se valorará la aplicación de habilidades adquiridas en esta práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.14  Python-3.11.5 torch-2.5.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=C://Users//ADMIN//anaconda3//envs//Antonio_P1//datasets//datasets_matricula//data.yaml, epochs=40, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cuda, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train3\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLO11n summary: 319 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train3', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLO11n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\ADMIN\\anaconda3\\envs\\Antonio_P1\\datasets\\datasets_matricula\\train\\labels... 7057 images, 5 backgrounds, 0 corrupt: 100%|██████████| 7057/7057 [00:03<00:00, 2272.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\ADMIN\\anaconda3\\envs\\Antonio_P1\\datasets\\datasets_matricula\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\ADMIN\\anaconda3\\envs\\Antonio_P1\\datasets\\datasets_matricula\\valid\\labels... 2048 images, 3 backgrounds, 0 corrupt: 100%|██████████| 2048/2048 [00:01<00:00, 1257.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\ADMIN\\anaconda3\\envs\\Antonio_P1\\datasets\\datasets_matricula\\valid\\labels.cache\n",
      "Plotting labels to runs\\detect\\train3\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train3\u001b[0m\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/40      2.46G       1.26      1.561      1.126          2        640: 100%|██████████| 442/442 [01:20<00:00,  5.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.941      0.865      0.914       0.57\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/40      2.43G      1.278     0.8945      1.146          1        640: 100%|██████████| 442/442 [01:07<00:00,  6.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.877      0.833      0.873      0.557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/40      2.42G      1.269     0.7922      1.151          1        640: 100%|██████████| 442/442 [01:05<00:00,  6.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.926      0.883      0.913      0.572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/40      2.42G      1.254     0.7498      1.141          1        640: 100%|██████████| 442/442 [01:07<00:00,  6.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.938      0.901      0.933      0.609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/40      2.42G      1.225     0.7005      1.122          1        640: 100%|██████████| 442/442 [01:05<00:00,  6.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.952        0.9      0.929      0.614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/40      2.42G      1.202     0.6604      1.114          2        640: 100%|██████████| 442/442 [01:04<00:00,  6.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.949      0.898      0.938      0.618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/40      2.42G      1.187     0.6388      1.101          6        640: 100%|██████████| 442/442 [01:05<00:00,  6.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195       0.95      0.902      0.939      0.634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/40      2.41G      1.178     0.6238      1.096          2        640: 100%|██████████| 442/442 [01:06<00:00,  6.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.972      0.918       0.95      0.626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/40      2.41G      1.173     0.6164      1.091          1        640: 100%|██████████| 442/442 [01:05<00:00,  6.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195       0.98      0.912      0.954      0.636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/40      2.41G       1.16     0.6037      1.087          1        640: 100%|██████████| 442/442 [01:06<00:00,  6.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.971      0.918      0.954      0.654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/40      2.41G      1.152      0.591      1.081          1        640: 100%|██████████| 442/442 [01:05<00:00,  6.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195       0.97      0.923      0.956      0.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/40      2.43G      1.145     0.5856       1.08          0        640: 100%|██████████| 442/442 [01:05<00:00,  6.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.973      0.922      0.959       0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/40      2.42G      1.146      0.574       1.08          3        640: 100%|██████████| 442/442 [01:06<00:00,  6.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.974      0.913      0.951      0.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/40      2.42G       1.13     0.5574      1.074          1        640: 100%|██████████| 442/442 [01:05<00:00,  6.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.946      0.915      0.946      0.653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/40      2.42G      1.136     0.5599       1.08          3        640: 100%|██████████| 442/442 [01:05<00:00,  6.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.976      0.922      0.958       0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/40      2.42G      1.118     0.5419      1.063          1        640: 100%|██████████| 442/442 [01:06<00:00,  6.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.974      0.924      0.963      0.672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/40      2.41G      1.108     0.5301      1.061          1        640: 100%|██████████| 442/442 [01:05<00:00,  6.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.968      0.929      0.958       0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/40      2.42G      1.107     0.5333      1.062          2        640: 100%|██████████| 442/442 [01:05<00:00,  6.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.972      0.918      0.962       0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/40      2.42G      1.109     0.5318       1.06          2        640: 100%|██████████| 442/442 [01:06<00:00,  6.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.974      0.935      0.966      0.674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/40      2.41G      1.093     0.5129      1.055          1        640: 100%|██████████| 442/442 [01:05<00:00,  6.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.982      0.925      0.963      0.675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/40      2.43G       1.09     0.5166      1.056          1        640: 100%|██████████| 442/442 [01:05<00:00,  6.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.975      0.928      0.966      0.677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/40      2.41G      1.094     0.5093      1.053          1        640: 100%|██████████| 442/442 [01:05<00:00,  6.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.981      0.927      0.964       0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/40      2.41G      1.087     0.5046       1.05          0        640: 100%|██████████| 442/442 [01:06<00:00,  6.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.983      0.934      0.967      0.678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/40      2.42G      1.075     0.4974      1.047          1        640: 100%|██████████| 442/442 [01:06<00:00,  6.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.986       0.93      0.966       0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/40      2.42G      1.076     0.4975      1.049          2        640: 100%|██████████| 442/442 [01:06<00:00,  6.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.985      0.929      0.964      0.682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/40      2.42G      1.073     0.4937      1.048          2        640: 100%|██████████| 442/442 [01:05<00:00,  6.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.975      0.938      0.968       0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/40      2.41G      1.066     0.4888      1.043          1        640: 100%|██████████| 442/442 [01:04<00:00,  6.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.975      0.935       0.97      0.685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/40      2.42G      1.065     0.4821      1.038          2        640: 100%|██████████| 442/442 [01:06<00:00,  6.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.979      0.937      0.968      0.689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/40      2.42G      1.051     0.4685      1.038          2        640: 100%|██████████| 442/442 [01:06<00:00,  6.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.979      0.937       0.97      0.692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/40      2.41G       1.05     0.4709      1.037          1        640: 100%|██████████| 442/442 [01:07<00:00,  6.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.984      0.935       0.97      0.692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/40      2.52G      1.052     0.4305      1.052          1        640: 100%|██████████| 442/442 [01:03<00:00,  6.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.984       0.93      0.969      0.692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/40      2.41G       1.04     0.4227      1.042          1        640: 100%|██████████| 442/442 [01:05<00:00,  6.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.981      0.939      0.971      0.694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/40      2.41G      1.037     0.4191      1.039          1        640: 100%|██████████| 442/442 [01:04<00:00,  6.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.983      0.935      0.969      0.691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/40      2.41G      1.034     0.4136      1.043          1        640: 100%|██████████| 442/442 [01:04<00:00,  6.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.979      0.944      0.971      0.694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/40      2.41G      1.022     0.4074      1.028          1        640: 100%|██████████| 442/442 [01:04<00:00,  6.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.978      0.939      0.969      0.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/40      2.41G       1.02     0.4007      1.025          1        640: 100%|██████████| 442/442 [01:04<00:00,  6.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.982      0.946      0.969      0.696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/40      2.41G      1.015     0.3957      1.026          1        640: 100%|██████████| 442/442 [01:04<00:00,  6.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.983      0.936      0.968      0.695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/40      2.41G      1.008     0.3941      1.028          1        640: 100%|██████████| 442/442 [01:04<00:00,  6.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195       0.98      0.941      0.969        0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/40      2.41G      0.997     0.3857      1.023          1        640: 100%|██████████| 442/442 [01:04<00:00,  6.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.988      0.937      0.969        0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/40      2.42G     0.9973     0.3804      1.022          1        640: 100%|██████████| 442/442 [01:05<00:00,  6.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.983      0.942       0.97      0.701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "40 epochs completed in 0.899 hours.\n",
      "Optimizer stripped from runs\\detect\\train3\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from runs\\detect\\train3\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating runs\\detect\\train3\\weights\\best.pt...\n",
      "Ultralytics 8.3.14  Python-3.11.5 torch-2.5.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "YOLO11n summary (fused): 238 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:15<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.983      0.942       0.97        0.7\n",
      "Speed: 0.2ms preprocess, 1.9ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "ruta = \"C://Users//ADMIN//anaconda3//envs//Antonio_P1//datasets//datasets_matricula//data.yaml\"\n",
    "\n",
    "# Verifica si CUDA está disponible\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Carga el modelo en el dispositivo especificado\n",
    "model = YOLO('yolo11n.pt').to(device)\n",
    "\n",
    "# Configura y ejecuta el entrenamiento\n",
    "results = model.train(data=ruta, epochs=40, imgsz=640, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 car, 92.7ms\n",
      "Speed: 3.0ms preprocess, 92.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 352x640 1 License_Plate, 79.0ms\n",
      "Speed: 2.0ms preprocess, 79.0ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "Matricula Detectada: 269LKL\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2  \n",
    "from ultralytics import YOLO\n",
    "import pytesseract\n",
    "import supervision as sv\n",
    "from supervision.draw.color import ColorPalette\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "# Se carga el modelo de Yolo11\n",
    "model_person_and_car = YOLO('yolo11n.pt').to('cpu')\n",
    "\n",
    "# Se lee la imagen que vamos a utilizar de prueba.\n",
    "image = cv2.imread(\"cochematricula.webp\")\n",
    "\n",
    "# Funcion utilizada para devolver la imagen de la caja delimitadora del objeto detectado \n",
    "def cropped(detections, image):\n",
    "    bounding_box = detections.xyxy\n",
    "    xmin, ymin, xmax, ymax = bounding_box[0]\n",
    "    xmin, ymin, xmax, ymax = int(xmin), int(ymin), int(xmax), int(ymax)\n",
    "    return image[ymin:ymax, xmin:xmax]\n",
    "\n",
    "\n",
    "# Recogeremos el primer resultado del modelo de personas y coches de Yolo11\n",
    "result = model_person_and_car(image)[0]\n",
    "\n",
    "# Nos permite manejar las detecciones de forma mas sencilla\n",
    "detections_t = sv.Detections.from_ultralytics(result)\n",
    "\n",
    "# Clase de interes 2 porque, 2 = Car\n",
    "class_id_of_interest = [2]\n",
    "\n",
    "\n",
    "mask = [class_id in class_id_of_interest for class_id in detections_t.class_id]\n",
    "if any(mask):\n",
    "\n",
    "    # Inicializamos las etiquetas\n",
    "    bounding_box_annotator = sv.BoundingBoxAnnotator()\n",
    "    label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "    # Se pasa la informacion que se mostrara en las etiquetas\n",
    "    annotated_image_t = bounding_box_annotator.annotate(scene=image, detections=detections_t)\n",
    "    annotated_image_t = label_annotator.annotate(scene=annotated_image_t, detections=detections_t)\n",
    "\n",
    "    # Aplicamos la funcion comentada anteriormente para tener una imagen mas directa de car detectado\n",
    "    cropped_image_t = cropped(detections_t, image)\n",
    "\n",
    "    # Aplicamos ahora el modelo especializado en matriculas de coches.\n",
    "    model_p = YOLO('best2.pt').to('cpu')\n",
    "\n",
    "    # Modificamos el nombre que trae por defecto el modelo a \"Matricula\"\n",
    "    results_p = model_p(cropped_image_t, agnostic_nms = True)[0]\n",
    "    results_p.names[0] = \"Matricula\"\n",
    "\n",
    "    detections_p = sv.Detections.from_ultralytics(results_p)\n",
    "\n",
    "    # Aplicamos la funcion comentada anteriormente para tener una imagen mas directa de la matricula\n",
    "    cropped_image_matricula = cropped(detections_p, cropped_image_t)\n",
    "\n",
    "    # Extraemos las coordenadas de la matricula y realizamos una diferencia para pasarlas a la imagen original\n",
    "    dif_x = results_p.boxes.xyxy[0][2] - results_p.boxes.xyxy[0][0]\n",
    "    dif_y = results_p.boxes.xyxy[0][3] - results_p.boxes.xyxy[0][1]\n",
    "\n",
    "    # Puntos iniciales, suma del punto de deteccion de la matricula mas el del coche\n",
    "    x1_nuevo = detections_t.xyxy[0][0] + detections_p.xyxy[0][0]\n",
    "    y1_nuevo = detections_t.xyxy[0][1] + detections_p.xyxy[0][1]\n",
    "\n",
    "    # Puntos finales, suma del pueto inicial mas las dimensiones de la box de matricula\n",
    "    x2_nuevo = x1_nuevo + dif_x  \n",
    "    y2_nuevo = y1_nuevo + dif_y \n",
    "\n",
    "    # Guardamos las coordenadas\n",
    "    detections_p.xyxy = np.array([[x1_nuevo,y1_nuevo,x2_nuevo,y2_nuevo]])\n",
    "\n",
    "    # Inicializamos las etiquetas de la matricula\n",
    "    bounding_box_annotator = sv.BoundingBoxAnnotator()\n",
    "    label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "    # Se pasa la informacion que se mostrara en las etiquetas\n",
    "    annotated_image_p = bounding_box_annotator.annotate(scene=image, detections=detections_p)\n",
    "    annotated_image_p = label_annotator.annotate(scene=annotated_image_p, detections=detections_p)\n",
    "\n",
    "    # Pasamos la imagen a gris y con el OCR, detectamos las letras de la matricula y las mostraremos por pantalla\n",
    "    gray = cv2.cvtColor(cropped_image_matricula, cv2.COLOR_BGR2GRAY)\n",
    "    data = pytesseract.image_to_string(gray, lang='eng', config='--psm 10 --oem 3 -c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYXabcdefghijklmnopqrstuvwxyz')\n",
    "\n",
    "    # Limpieza de la cadena de salida del OCR\n",
    "    valor_medio = round(len(data)/2)\n",
    "    data = data[valor_medio-3:valor_medio+4]\n",
    "    print(\"Matricula Detectada:\",data)\n",
    "    text = \"Matricula: \"+data\n",
    "\n",
    "    # Defininimos la posicion del texto, fuente, tamaño, color y grosor de este\n",
    "    position = (300, 90)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 1\n",
    "    font_color = (255, 255, 255)\n",
    "    font_thickness = 2\n",
    "\n",
    "    #Añadimos el texto a la imagen\n",
    "    annotated_image_p = cv2.putText(annotated_image_p, text, position, font, font_scale, font_color, font_thickness)\n",
    "        \n",
    "#Mostramos por consola la imagen resultante\n",
    "sv.plot_image(annotated_image_p)\n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando el dispositivo: cuda\n",
      "Conteo total de personas: 3715\n",
      "Conteo total de coches: 23394\n",
      "Conteo total de matrículas: 1474\n",
      "Video guardado en: c:\\Users\\ADMIN\\anaconda3\\envs\\Antonio_P1\\output_video.mp4\n",
      "CSV de detecciones guardado en: c:\\Users\\ADMIN\\anaconda3\\envs\\Antonio_P1\\detections.csv\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import pytesseract\n",
    "import supervision as sv\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Eliminamos los posibles warning que salgan por consola.\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Configuración de CUDA\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Usando el dispositivo: {device}\")\n",
    "\n",
    "# Cargar modelos y usamos el device detectado preferiblemente CUDA\n",
    "model_person_and_car = YOLO('yolo11n.pt').to(device)\n",
    "model_p = YOLO('best2.pt').to(device)\n",
    "\n",
    "# Inicializamos captura de video\n",
    "cap = cv2.VideoCapture('C0142.mp4')\n",
    "\n",
    "# Configuración para guardar el video de salida\n",
    "output_video_path = os.path.join(os.getcwd(), 'output_video.mp4')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, cap.get(cv2.CAP_PROP_FPS), \n",
    "                      (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "# Archivo CSV para registrar las detecciones\n",
    "csv_file_path = os.path.join(os.getcwd(), 'detections.csv')\n",
    "with open(csv_file_path, mode='w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow([\n",
    "        'Frame', 'Object_Type', 'Confidence', 'Tracking_ID', 'x1', 'y1', 'x2', 'y2', \n",
    "        'License_Plate_Detected', 'Plate_Confidence', 'mx1', 'my1', 'mx2', 'my2', 'Plate_Text'\n",
    "    ])\n",
    "\n",
    "# Contadores de detección\n",
    "total_personas = 0\n",
    "total_coches = 0\n",
    "total_matriculas = 0\n",
    "\n",
    "# Función para recortar la imagen según la detección\n",
    "def cropped(detections, image):\n",
    "    if detections.xyxy.shape[0] > 0:\n",
    "        xmin, ymin, xmax, ymax = map(int, detections.xyxy[0])\n",
    "        return image[ymin:ymax, xmin:xmax]\n",
    "    return None\n",
    "\n",
    "# Definimos una función para desenfocar la región detectada en una imagen\n",
    "def desenfocar_zona(frame, bbox):\n",
    "    x1, y1, x2, y2 = map(int, bbox)\n",
    "    # Aquí puedes ajustar cuánto del área superior deseas desenfocar\n",
    "    y_top = y1 + int((y2 - y1) * 0.5)  # desenfocar solo la mitad superior del cuerpo\n",
    "    # Aplicar un desenfoque sobre la región superior\n",
    "    frame[y1:y_top, x1:x2] = cv2.GaussianBlur(frame[y1:y_top, x1:x2], (51, 51), 30)\n",
    "\n",
    "# Contador de frames para en el CSV establecer en que frame se detecto dicha detección\n",
    "frame_number = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_number += 1\n",
    "    # Detección de personas y autos en el frame original\n",
    "    result = model_person_and_car(frame, verbose=False)[0]\n",
    "    detections_t = sv.Detections.from_ultralytics(result)\n",
    "    \n",
    "    # Por cada detección recogemos la clase, la confianza, el id de seguimiento y sus coordenadas\n",
    "    for detection in detections_t:\n",
    "        if detection is None or len(detection) < 5:\n",
    "            continue\n",
    "\n",
    "        obj_class = detection[5]['class_name'] # Clase\n",
    "        confidence = detection[2]  # Confianza\n",
    "        tracking_id = detection[3]  # ID de seguimiento\n",
    "        bbox = detection[0] # Coordenadas\n",
    "        \n",
    "        # Definimos el tipo de clase detectada y si es aumentamos en 1 el contador de dicha clase (Persona o Coche)\n",
    "        if obj_class == 'person':  # Persona\n",
    "            desenfocar_zona(frame, bbox)\n",
    "            obj_type = 'Person'\n",
    "            total_personas += 1\n",
    "        elif obj_class == 'car':  # Coche\n",
    "            obj_type = 'Car'\n",
    "            total_coches += 1\n",
    "        else:\n",
    "            continue  # Ignorar otras clases\n",
    "\n",
    "        # Guardamos la detección en el CSV\n",
    "        with open(csv_file_path, mode='a', newline='') as csv_file:\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "            csv_writer.writerow([\n",
    "            frame_number, obj_type, confidence, tracking_id, bbox[0], bbox[1], bbox[2], bbox[3], '', '', '', '', '', ''\n",
    "            ])\n",
    "    \n",
    "    # Procesar matrículas en las detecciones de coches\n",
    "    class_id_of_interest = [2]  # Solo coches\n",
    "    mask = [class_id in class_id_of_interest for class_id in detections_t.class_id]\n",
    "    \n",
    "    # Registramos ahora las etiquetas\n",
    "    bounding_box_annotator = sv.BoundingBoxAnnotator()\n",
    "    label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "    # Anotar todas las detecciones en el frame\n",
    "    annotated_frame = bounding_box_annotator.annotate(scene=frame, detections=detections_t)\n",
    "    annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=detections_t)\n",
    "\n",
    "    if any(mask):\n",
    "        # Recortar el área del coche y verificar que el recorte no sea None\n",
    "        cropped_image_t = cropped(detections_t, frame)\n",
    "        if cropped_image_t is not None:\n",
    "\n",
    "            # Una vez tengamos la imagen resultante le aplicamos un resize con la mayor resolucion posible para trabajar con CUDA\n",
    "            cropped_image_resized = cv2.resize(cropped_image_t, (832, 512))\n",
    "            results_p = model_p(cropped_image_resized, verbose=False)[0] #Aplicamos el modelo y tomamos solo el primer resultado\n",
    "            detections_p = sv.Detections.from_ultralytics(results_p)\n",
    "\n",
    "            # Nos aseguramos de que las coordenadas de la caja delimitadora sean superiores a 0 de la primera detección\n",
    "            if detections_p.xyxy.shape[0] > 0:\n",
    "\n",
    "                # Ahora por cada detection en detections_p tomaremos sus coordenadas y confianza\n",
    "                for detection in detections_p:\n",
    "                    total_matriculas += 1 # Aumentamos el contador de matricula\n",
    "                    plate_bbox = detection[0] # Coordendas de la matricula\n",
    "                    plate_confidence = detection[2] # Confianza de la matricula\n",
    "                    px1, py1, px2, py2 = map(int, plate_bbox) # Dividimos las coordenadas en 4 variables\n",
    "                cropped_image_matricula = cropped(detections_p, cropped_image_resized)\n",
    "                \n",
    "                # Si a la hora de recoger la imagen resultante de la caja delimitadora de la matricula no da fallo entramos en el condicional\n",
    "                if cropped_image_matricula is not None:\n",
    "\n",
    "                    # Misma logica que en el anterior codigo, pasamos a gris y aplicamos OCR detectando las letras de la matricula\n",
    "                    gray = cv2.cvtColor(cropped_image_matricula, cv2.COLOR_BGR2GRAY)\n",
    "                    data = pytesseract.image_to_string(\n",
    "                        gray, lang='eng', config='--psm 10 --oem 3 -c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "                    )\n",
    "\n",
    "                    # Limpieza del texto de la matrícula\n",
    "                    data = data.strip()[:7]  # Solo primeros 7 caracteres\n",
    "\n",
    "                    # Colocar el texto en el frame\n",
    "                    position = (int(detections_t.xyxy[0][0]), int(detections_t.xyxy[0][1]) - 10)\n",
    "                    annotated_frame = cv2.putText(annotated_frame, f\"Matricula: {data}\", position, cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "\n",
    "                    # Guardar en el CSV\n",
    "                    with open(csv_file_path, mode='a', newline='') as csv_file:\n",
    "                        csv_writer = csv.writer(csv_file)\n",
    "                        csv_writer.writerow([\n",
    "                            frame_number, 'License Plate', confidence, tracking_id, bbox[0], bbox[1], bbox[2], bbox[3],\n",
    "                            'Yes', plate_confidence, px1, py1, px2, py2, data\n",
    "                        ])\n",
    "\n",
    "    # Escribir el frame anotado en el video de salida\n",
    "    out.write(annotated_frame)\n",
    "    cv2.imshow('Video', annotated_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Resumen en consola\n",
    "print(f\"Conteo total de personas: {total_personas}\")\n",
    "print(f\"Conteo total de coches: {total_coches}\")\n",
    "print(f\"Conteo total de matrículas: {total_matriculas}\")\n",
    "print(f\"Video guardado en: {output_video_path}\")\n",
    "print(f\"CSV de detecciones guardado en: {csv_file_path}\")\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Antonio_P1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
